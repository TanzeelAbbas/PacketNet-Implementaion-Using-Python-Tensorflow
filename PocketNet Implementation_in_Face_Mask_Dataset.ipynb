{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66936f12",
      "metadata": {
        "id": "66936f12"
      },
      "source": [
        "# Face Mask Detection Project"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3063961e",
      "metadata": {
        "id": "3063961e"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24f131d1",
      "metadata": {
        "id": "24f131d1"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers, optimizers, models\n",
        "from keras.layers import Conv2D, BatchNormalization, PReLU, MaxPooling2D\n",
        "from keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "R6IeO40_zlbl"
      },
      "id": "R6IeO40_zlbl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/MyDrive/Face Dataset.zip\", 'r')\n",
        "zip_ref.extractall(\"/content/drive/MyDrive\")\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "KOOMTMMz2ZrM"
      },
      "id": "KOOMTMMz2ZrM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "69f1fa92",
      "metadata": {
        "id": "69f1fa92"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3dfbaff3",
      "metadata": {
        "id": "3dfbaff3"
      },
      "outputs": [],
      "source": [
        "data_path=\"/content/drive/MyDrive/Face Dataset\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73511f6a",
      "metadata": {
        "id": "73511f6a"
      },
      "outputs": [],
      "source": [
        "train_data_path=os.path.join(data_path, 'Train Data')\n",
        "val_data_path=os.path.join(data_path, 'Validation Data')\n",
        "test_data_path=os.path.join(data_path, \"Test Data\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c000204f",
      "metadata": {
        "id": "c000204f"
      },
      "outputs": [],
      "source": [
        "names=os.listdir(train_data_path)\n",
        "names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31ad91ab",
      "metadata": {
        "id": "31ad91ab"
      },
      "outputs": [],
      "source": [
        "def total_img(path,names):\n",
        "    count=0\n",
        "    for name in names:\n",
        "        size=len(os.listdir(os.path.join(path, name)))\n",
        "        count+=size\n",
        "    return count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "256b5c75",
      "metadata": {
        "id": "256b5c75"
      },
      "outputs": [],
      "source": [
        "print(\"Total Training Images: \", total_img(train_data_path, names))\n",
        "print(\"Total Validation Images: \", total_img(val_data_path, names))\n",
        "print(\"Total Test Images: \", total_img(test_data_path, names))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd7f8d28",
      "metadata": {
        "id": "cd7f8d28"
      },
      "source": [
        "# Data preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "173aadbc",
      "metadata": {
        "id": "173aadbc"
      },
      "source": [
        "# Using ImageDataGenerator to read images from directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9883301e",
      "metadata": {
        "id": "9883301e"
      },
      "outputs": [],
      "source": [
        "datagenerator=ImageDataGenerator( \n",
        "                                   rescale=1./255,\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bded4a20",
      "metadata": {
        "id": "bded4a20"
      },
      "outputs": [],
      "source": [
        "train_gen= datagenerator.flow_from_directory(\n",
        "                                              train_data_path,\n",
        "                                              batch_size=39,\n",
        "                                              target_size=(56,56),\n",
        "                                              class_mode='binary'\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "38cab314",
      "metadata": {
        "id": "38cab314"
      },
      "outputs": [],
      "source": [
        "val_gen= datagenerator.flow_from_directory(\n",
        "                                            val_data_path,\n",
        "                                            target_size=(56,56),\n",
        "                                            batch_size=26,\n",
        "                                            class_mode='binary'\n",
        "                                        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f895ff36",
      "metadata": {
        "id": "f895ff36"
      },
      "outputs": [],
      "source": [
        "labels=train_gen.class_indices\n",
        "labels"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2bdb969f",
      "metadata": {
        "id": "2bdb969f"
      },
      "source": [
        "# Network Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5384a85c",
      "metadata": {
        "id": "5384a85c"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, Conv2D, Add, Activation\n",
        "\n",
        "def normal_cell(x, n_filters, n_inputs, n_operations, n_outputs):\n",
        "    inputs = [x]\n",
        "    for i in range(n_inputs):\n",
        "        inputs.append(Input(shape=(None, None, n_filters)))\n",
        "\n",
        "    operations = []\n",
        "    for i in range(n_operations):\n",
        "        operation = Conv2D(filters=n_filters, kernel_size=3, strides=1, padding='same')(x)\n",
        "        operations.append(operation)\n",
        "\n",
        "    x = Add()(operations)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "de441a76",
      "metadata": {
        "id": "de441a76"
      },
      "outputs": [],
      "source": [
        "from keras.layers import Input, MaxPooling2D, Conv2D, Concatenate\n",
        "\n",
        "def reduction_cell(x, n_filters):\n",
        "    # apply max pooling with stride 2\n",
        "    x = MaxPooling2D(strides=2, padding='same')(x)\n",
        "    \n",
        "    # apply 1x1 convolution with n_filters\n",
        "    c1 = Conv2D(n_filters, kernel_size=1, activation='relu', padding='same')(x)\n",
        "    \n",
        "    # apply 3x3 convolution with n_filters\n",
        "    c2 = Conv2D(n_filters, kernel_size=3, activation='relu', padding='same')(x)\n",
        "    \n",
        "    # concatenate the outputs of the 1x1 and 3x3 convolution\n",
        "    x = Concatenate()([c1, c2])\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccdf9273",
      "metadata": {
        "id": "ccdf9273"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Input tensor\n",
        "inputs = Input(shape=(56, 56, 3))\n",
        "\n",
        "# 2D convolutional layer\n",
        "x = Conv2D(128, (3, 3), strides=(2, 2), padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "# Normal cell\n",
        "x = normal_cell(x, n_filters=128, n_inputs=3, n_operations=6, n_outputs=1)\n",
        "\n",
        "# Reduction cell\n",
        "x = reduction_cell(x, n_filters=256)\n",
        "\n",
        "# Normal cell\n",
        "x = normal_cell(x, n_filters=256, n_inputs=7, n_operations=11, n_outputs=2)\n",
        "\n",
        "# Reduction cell\n",
        "x = reduction_cell(x, n_filters=512)\n",
        "\n",
        "# Normal cell\n",
        "x = normal_cell(x, n_filters=512, n_inputs=12, n_operations=15, n_outputs=1)\n",
        "\n",
        "# Reduction cell\n",
        "x = reduction_cell(x, n_filters=1024)\n",
        "\n",
        "# PReLU activation and convolutional layer\n",
        "x = PReLU()(x)\n",
        "x = Conv2D(512, (1, 1), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = PReLU()(x)\n",
        "# Final convolutional layers\n",
        "x = Conv2D(512, (7, 7), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Conv2D(128, (1, 1), padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "\n",
        "x=layers.Flatten()(x)\n",
        "x=layers.Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "# Create the model\n",
        "model = Model(inputs, x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af2178a9",
      "metadata": {
        "id": "af2178a9"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a48d141",
      "metadata": {
        "id": "4a48d141"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=optimizers.RMSprop(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4613c9e4",
      "metadata": {
        "id": "4613c9e4"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7814912b",
      "metadata": {
        "id": "7814912b",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "history=model.fit(train_gen, epochs=15, validation_data=val_gen)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d4c8dbf",
      "metadata": {
        "id": "7d4c8dbf"
      },
      "outputs": [],
      "source": [
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "epochs = range(1, len(acc) + 1)\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u1P1PBSxBKdO",
      "metadata": {
        "id": "u1P1PBSxBKdO"
      },
      "outputs": [],
      "source": [
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "epochs= range(1,len(loss)+1)\n",
        "plt.plot(epochs, loss, 'bo', label=\"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', label=\"Validation Loss\" )\n",
        "plt.title(\"Training and Validation Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dgdsBb-FC4Sb",
      "metadata": {
        "id": "dgdsBb-FC4Sb"
      },
      "outputs": [],
      "source": [
        "model.save(\"/content/drive/MyDrive/Face Mask Detection Project/face detection new model.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "od0oogJTDtM1",
      "metadata": {
        "id": "od0oogJTDtM1"
      },
      "outputs": [],
      "source": [
        "testdatagen=ImageDataGenerator(rescale=1./255)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jh8qDmJ_QFlN",
      "metadata": {
        "id": "Jh8qDmJ_QFlN"
      },
      "outputs": [],
      "source": [
        "test_generator=testdatagen.flow_from_directory(\n",
        "                                            test_data_path,\n",
        "                                            batch_size=12,\n",
        "                                            target_size=(56,56),\n",
        "                                            class_mode='binary'\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "n53s9vsqQWDe",
      "metadata": {
        "id": "n53s9vsqQWDe"
      },
      "outputs": [],
      "source": [
        "loss,acc= model.evaluate(test_generator)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "i332k0HqQiKd",
      "metadata": {
        "id": "i332k0HqQiKd"
      },
      "outputs": [],
      "source": [
        "print(\"Test Data Loss: \",loss)\n",
        "print(\"Test Data Accuracy: \",acc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "054ceb16",
      "metadata": {
        "id": "054ceb16"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}